{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c69b66e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\pndes\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from deepface import DeepFace\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tkinter import Tk, filedialog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42302aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# ðŸ”¹ STEP 1: Install dependencies (run in a cell if not installed)\n",
    "# ============================================\n",
    "# !pip install deepface opencv-python matplotlib ipywidgets\n",
    "\n",
    "# ============================================\n",
    "# ðŸ”¹ STEP 2: Import libraries\n",
    "# ============================================\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from deepface import DeepFace\n",
    "import numpy as np\n",
    "\n",
    "# ============================================\n",
    "# ðŸ”¹ STEP 3: File Upload Widget\n",
    "# ============================================\n",
    "upload = widgets.FileUpload(accept='image/*', multiple=False)\n",
    "display(upload)\n",
    "\n",
    "# Wait until a file is uploaded\n",
    "while not upload.value:\n",
    "    pass\n",
    "\n",
    "# Load uploaded image\n",
    "file_info = list(upload.value.values())[0]\n",
    "image_bytes = file_info['content']\n",
    "nparr = np.frombuffer(image_bytes, np.uint8)\n",
    "img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
    "\n",
    "# Save temporarily because DeepFace needs a file path\n",
    "tmp_path = \"temp_image.jpg\"\n",
    "cv2.imwrite(tmp_path, img)\n",
    "\n",
    "# ============================================\n",
    "# ðŸ”¹ STEP 4: Run Facial-Expression Analysis\n",
    "# ============================================\n",
    "analysis = DeepFace.analyze(\n",
    "    img_path=tmp_path,\n",
    "    actions=['emotion'],  # Can include ['age','gender','race'] too\n",
    "    enforce_detection=False\n",
    ")\n",
    "\n",
    "# Ensure analysis is a list (for multiple faces)\n",
    "if isinstance(analysis, dict):\n",
    "    analysis = [analysis]\n",
    "\n",
    "# ============================================\n",
    "# ðŸ”¹ STEP 5: Print Analysis Results\n",
    "# ============================================\n",
    "print(\"\\nâœ… Facial-Expression Analysis Results:\\n\")\n",
    "for idx, face in enumerate(analysis, start=1):\n",
    "    print(f\"Face {idx}:\")\n",
    "    print(\"  Dominant Emotion:\", face['dominant_emotion'])\n",
    "    print(\"  All Emotion Probabilities:\", face['emotion'])\n",
    "    print(\"  Region:\", face['region'], \"\\n\")\n",
    "\n",
    "# ============================================\n",
    "# ðŸ”¹ STEP 6: Draw Bounding Boxes and Labels\n",
    "# ============================================\n",
    "for face in analysis:\n",
    "    region = face.get('region', {})\n",
    "    x = int(region.get('x', 0))\n",
    "    y = int(region.get('y', 0))\n",
    "    w = int(region.get('w', 0))\n",
    "    h = int(region.get('h', 0))\n",
    "\n",
    "    if w > 0 and h > 0:\n",
    "        # Draw bounding box\n",
    "        cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        # Label emotion\n",
    "        cv2.putText(img, face['dominant_emotion'], (x, max(y - 10, 0)),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "# ============================================\n",
    "# ðŸ”¹ STEP 7: Display Annotated Image\n",
    "# ============================================\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Detected Facial Expressions\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0rc3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
